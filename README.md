# StockMarketPrices
Introduction:
In modern finance, Stock market faces the major problem of finding efficient ways to condense and visualize into plots the stock market data to give investors useful information about the market trends and behaviour for making sound investment decisions. The humongous amounts of valuable is data generated by the stock market. With large amounts of data, comes greater possibilities to explore the problem domain using different methodologies. The significant benefits of solving these problems and gaining greater profits has motivated research for years. The research in this field has gained a high attraction due to the significance of its use in applications and the increasing generated information.
Financial market is a noisy, nonlinear, complex, nonstationary and dynamic system, so we will be using the KDD methodology to predict the closing prices of the data.

Data Mining Methodology:
To solve problems in the most efficient way, a researcher is expected to follow a standard process for the best understanding of the readers and for problem-solving. KDD is an apt standard methodology to fulfil our purpose. Knowledge Discovery in Databases is a part of data mining methodology that refers to the broad process of exploring data to discover previously unknown patterns. KDD is an iterative process that involves knowledge presentation, pattern evaluation, data cleaning, integration and transformation.

Data Collection:
We choose consecutive data of top two indices of the Bombay Stock Exchange from Quandl to perform our analysis. The indices involved in the analysis are Tata Steel and HDFC Limited. Prices of a company cannot be predicted only from the stock price itself. The data employed in this study consists of no. of shares, no. of traders, total turnover, Spread C-O (Close-Open), Spread H- L (High-Low), previous close, open price, high price and low price of both companies. The data set encompassed the trading days from 01-Jan-1991 to 27-April-2020. The historical data is extracted from Quandl by adding the API in the dataset and then converted to CSV for further manipulation.

Data Cleaning
The raw data obtained is in different formats with many garbage values which should be converted into a similar format to use data efficiently in building machine learning model. A thorough data cleaning is done in the dataset, to make it ready for selection and transformation. This step involves normalization, looking for outliers and taking care of missing values. Along with these steps, making the data clean by slicing spaces, symbols and unexpected values.
The data obtained for the stock indices is mostly clean data with missing values in two attributes (Deliverable Quantity and % of Deliverable Quantity Traded). These tuples are the low variance features so it is preferred to be dropped. While loading the data, the date column was not in the correct index as the dataset. This issue would not allow the date to be used for manipulation. Indexing is performed to solve the problem.

Data Selection and Transformation:
After getting rid of the unknown values and redundant columns, the data frame consists of 7094 rows and 12 columns. Resampling for the dependent variable is done where a monthly and quarterly average of the closed price is taken to see fluctuations.Looking at the correlation matrix the spread columns are taken for further analysis. The distributed plot looks negatively skewed. A log function is used to get the normality.

Training and Testing data:
For the application of machine learning algorithms, splitting the preprocessed data into training and testing tests by 75% and 25% respectively. Next step involves constructing a model on the training data using data mining models.

Methodology:
This section focuses on the supervised learning approaches to build a model on the data to obtain desired outputs. Regression and Classification are the instances of supervised learning.
Linear Regression is a statistical technique used to find the outcome or class along with attributes, when they are numeric. That output is a linear amalgamation of predetermined weights of the attributes. Below is the equation:
X = w0 + w1 a1 + w2 a2 + ..... + wk ak
where x is the outcome; a1,a2,..,ak are the attribute values and w1,w2,..,wk are the weights. The significant predictors of the ‘spread high-low’ prices attribute is no. of traders, closing price etc. A decent accuracy of 66% is obtained, which is a good chance for the stock market data.

Evaluation:
R-squared derives the correlation between the two variable which are the perceived outcome values and the forecasted values. The forecasted variables are found to be in proportion to the outcome. The higher is the value and much better is the model considered.

Results:
The stock market is the most tricky, analysing more factors like social media influence or the news, can change the stock prices dramatically. In this context, I have used Linear Regression the most basic model for evaluation. In future, predictions can be made on the basis of multidimensional data. There is still room for more improvement in models and evaluation methods.
